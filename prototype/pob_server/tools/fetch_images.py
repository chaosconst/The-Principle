import requests
from bs4 import BeautifulSoup
import sys
import os
from urllib.parse import urljoin

def fetch_first_image(url, save_name):
    print(f"üñºÔ∏è Scouting: {url} ...")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': url
    }
    
    try:
        r = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # ÊèêÂèñÊâÄÊúâÂõæÁâáÈìæÊé•
        images = []
        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src') or img.get('data-original')
            if src and src.startswith('http'):
                # ÁÆÄÂçïËøáÊª§ÔºöÊéíÈô§ÂõæÊ†á„ÄÅÂ§¥ÂÉèÁ≠âÂ∞èÂõæ
                if 'icon' not in src and 'avatar' not in src and '.svg' not in src:
                    images.append(src)
        
        # Â∞ùËØï‰∏ãËΩΩÁ¨¨‰∏ÄÂº†ÊúâÊïàÁöÑÂ§ßÂõæ (Â§ß‰∫é 10KB)
        for i, img_url in enumerate(images[:5]): # Âè™ËØïÂâç5Âº†
            try:
                print(f"  Trying image {i+1}: {img_url[:50]}...")
                img_data = requests.get(img_url, headers=headers, timeout=5).content
                if len(img_data) > 20000: # > 20KB
                    save_path = os.path.expanduser(f"~/pob_server/uploads/{save_name}.jpg")
                    with open(save_path, 'wb') as f:
                        f.write(img_data)
                    print(f"‚úÖ Captured: {save_path} ({len(img_data)//1024} KB)")
                    return
            except Exception as e:
                print(f"  Failed: {e}")
                continue
                
        print("‚ùå No valid large image found.")

    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python3 fetch_images.py <url> <save_name>")
    else:
        fetch_first_image(sys.argv[1], sys.argv[2])
